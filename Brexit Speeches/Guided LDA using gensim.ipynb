{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided LDA using gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a Guided LDA model, we need to provide the model with a list of topics and seed words. More often then not the topics we get from a standard, unsupervised LDA model are not to our satisfaction. Guided LDA can give the topics a nudge in the direction we want it to converge. We can call this a **semi-supervised LDA model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspiration for this notebook was provided by: https://gist.github.com/scign/2dda76c292ef76943e0cd9ff8d5a174a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraraies\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of additional subpackages that nltk requires to use the POS tagging feature and the WordNet model. We have to make sure those are downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the datasets from the EDA notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "boris_speech = pd.read_pickle(\"Pickled Files/boris_speech.pkl\")\n",
    "may_speech = pd.read_pickle(\"Pickled Files/may_speech.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am pleased that this campaign has so far bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>that rocked me  at first  and then i decided t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for many of us who are now deeply sceptical  t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence\n",
       "0  i am pleased that this campaign has so far bee...\n",
       "1  that rocked me  at first  and then i decided t...\n",
       "2  for many of us who are now deeply sceptical  t..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boris_speech.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>today i want to talk about the united kingdom ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>but before i start  i want to make clear that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sovereignty and membership of multilateral ins...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence\n",
       "0  today i want to talk about the united kingdom ...\n",
       "1  but before i start  i want to make clear that ...\n",
       "2  sovereignty and membership of multilateral ins..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "may_speech.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll create a corpus of text strings for each speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am pleased that this campaign has so far been relatively free of personal abuse   and long may it so remain   but the other day someone insulted me in terms that were redolent of     s soviet russia  he said that i had no right to vote leave  because i was in fact a  liberal cosmopolitan  \n",
      "that rocked me  at first  and then i decided that as insults go  i didn t mind it at all   because it was probably true  and so i want this morning to explain why the campaign to leave the eu is attracting other liberal spirits and people i admire such as david owen  and gisela stuart  nigel lawson  john longworth   people who love europe and who feel at home on the continent  but whose attitudes towards the project of european union have been hardening over time \n",
      "for many of us who are now deeply sceptical  the evolution has been roughly the same  we began decades ago to query the anti democratic absurdities of the eu  then we began to campaign for reform  and were excited in      by the prime minister s bloomberg speech  and then quietly despaired as no reform was forthcoming  and then thanks to the referendum given to this country by david cameron we find that a door has magically opened in our lives \n",
      "\n",
      "\n",
      "length of boris speech: 100 sentences\n",
      "\n",
      "today i want to talk about the united kingdom  our place in the world and our membership of the european union \n",
      "but before i start  i want to make clear that   as you can see   this is not a rally   it will not be an attack or even a criticism of people who take a different view to me   it will simply be my analysis of the rights and wrongs  the opportunities and risks  of our membership of the eu \n",
      "sovereignty and membership of multilateral institutions\n",
      "\n",
      "\n",
      "length of may speech: 74 sentences\n"
     ]
    }
   ],
   "source": [
    "boris_corp = list(boris_speech['Sentence'])\n",
    "may_corp = list(may_speech['Sentence'])\n",
    "\n",
    "for sentence in boris_corp[:3]:\n",
    "    print(sentence)\n",
    "print(\"\\n\")\n",
    "print(f\"length of boris speech: {len(boris_corp)} sentences\\n\")\n",
    "\n",
    "for sentence in may_corp[:3]:\n",
    "    print(sentence)\n",
    "print(\"\\n\")\n",
    "print(f\"length of may speech: {len(may_corp)} sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now perform some lemmatization using the nltk library in order to transform words into their root form (lemma.)\n",
    "\n",
    "To identify what part-of-speech any particular word is, is not easy, but nltk again comes to the rescue providing access to a part-of-speech tagger which returns a suitable tag for each word in a given text.\n",
    "\n",
    "The twist is that the nltk.pos_tag function returns the Penn Treebank tag for the word but we just want whether the word is a noun, verb, adjective or adverb. We need a short simplification routine to translate from the Penn tag to a simpler tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify Penn tags to n (NOUN), v (VERB), a (ADJECTIVE) or r (ADVERB)\n",
    "def simplify(penn_tag):\n",
    "    pre = penn_tag[0]\n",
    "    if (pre == 'J'):\n",
    "        return 'a'\n",
    "    elif (pre == 'R'):\n",
    "        return 'r'\n",
    "    elif (pre == 'V'):\n",
    "        return 'v'\n",
    "    else:\n",
    "        return 'n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform some preprocessing on the two corpuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    toks = gensim.utils.simple_preprocess(str(text), deacc=True)\n",
    "    wn = WordNetLemmatizer()\n",
    "    return [wn.lemmatize(tok, simplify(pos)) for tok, pos in nltk.pos_tag(toks) if tok not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boris:\n",
      "['pleased', 'campaign', 'far', 'relatively', 'free', 'personal', 'abuse', 'long', 'may', 'remain', 'day', 'someone', 'insult', 'term', 'redolent', 'soviet', 'russia', 'say', 'right', 'vote', 'leave', 'fact', 'liberal', 'cosmopolitan']\n",
      "['rock', 'first', 'decide', 'insult', 'go', 'mind', 'probably', 'true', 'want', 'morning', 'explain', 'campaign', 'leave', 'eu', 'attract', 'liberal', 'spirit', 'people', 'admire', 'david', 'owen', 'gisela', 'stuart', 'nigel', 'lawson', 'john', 'longworth', 'people', 'love', 'europe', 'feel', 'home', 'continent', 'whose', 'attitude', 'towards', 'project', 'european', 'union', 'harden', 'time']\n",
      "['many', 'deeply', 'sceptical', 'evolution', 'roughly', 'begin', 'decade', 'ago', 'query', 'anti', 'democratic', 'absurdity', 'eu', 'begin', 'campaign', 'reform', 'excite', 'prime', 'minister', 'bloomberg', 'speech', 'quietly', 'despair', 'reform', 'forthcoming', 'thanks', 'referendum', 'give', 'country', 'david', 'cameron', 'find', 'door', 'magically', 'open', 'life']\n",
      "May:\n",
      "['today', 'want', 'talk', 'united', 'kingdom', 'place', 'world', 'membership', 'european', 'union']\n",
      "['start', 'want', 'make', 'clear', 'see', 'rally', 'attack', 'even', 'criticism', 'people', 'take', 'different', 'view', 'simply', 'analysis', 'right', 'wrong', 'opportunity', 'risk', 'membership', 'eu']\n",
      "['sovereignty', 'membership', 'multilateral', 'institution']\n"
     ]
    }
   ],
   "source": [
    "boris_corp = [preprocess(line) for line in boris_corp]\n",
    "print(\"Boris:\")\n",
    "print(boris_corp[0])\n",
    "print(boris_corp[1])\n",
    "print(boris_corp[2])\n",
    "\n",
    "print(\"May:\")\n",
    "may_corp = [preprocess(line) for line in may_corp]\n",
    "print(may_corp[0])\n",
    "print(may_corp[1])\n",
    "print(may_corp[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the lemmatizing functions have performed their task very well in putting the words into their root form depending on the POS tag. We've also removed any more lingering stopwords which is excellent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowflakes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
