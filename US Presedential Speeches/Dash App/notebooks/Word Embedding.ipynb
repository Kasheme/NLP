{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Word Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from top2vec import Top2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Top2Vec.load(\"C:\\\\Users\\\\User\\\\OneDrive\\\\Documents\\\\GitHub\\\\NLP\\\\US Presedential Speeches\\\\Analysis\\\\Topic Modelling\\\\US_Speech_Top2Vec_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import functions as fnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.read_pickle(\"C:\\\\Users\\\\User\\\\OneDrive\\\\Documents\\\\GitHub\\\\NLP\\\\US Presedential Speeches\\\\Analysis\\\\Topic Modelling\\\\speech_documents.pkl\")\n",
    "words = fnc.df_to_list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(str(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53381"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are 0.9181389309439607\n",
      "that 0.8905951293796122\n",
      "in 0.8807695170342631\n",
      "more 0.8790426949029475\n",
      "not 0.8743228729834158\n",
      "these 0.8738796335611863\n",
      "work 0.8738499130133635\n",
      "but 0.8736078208843514\n",
      "there 0.8701643567718098\n",
      "would 0.8690937579024536\n",
      "many 0.8673838969876138\n",
      "american 0.8651830199150358\n",
      "or 0.8628412309637132\n",
      "up 0.858749960736025\n",
      "troops 0.8514404239491151\n",
      "america 0.8505185059910716\n",
      "it 0.8488579872006736\n",
      "americans 0.8451927842682192\n",
      "with 0.8438658373999004\n",
      "world 0.8389185250910689\n"
     ]
    }
   ],
   "source": [
    "words, word_scores = model.similar_words(keywords=['terrorists'], keywords_neg=[], num_words=20)\n",
    "for word, score in zip(words, word_scores):\n",
    "    print(f\"{word} {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainbow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
